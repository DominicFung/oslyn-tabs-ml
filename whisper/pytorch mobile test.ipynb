{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Whisper\n",
    "\n",
    "OpenAI Whisper is one of the many state-of-the-art, ASR models. \n",
    "\n",
    "- Run Pretrained Model\n",
    "- Transform Pretrained Model to TFlite OR TensorFlow Mobile\n",
    "- Validate Integration with NextJS\n",
    "- Validate Integration with React Native\n",
    "- Provide Additional Training Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -q -y optimum-intel optimum\n",
    "!pip install -q transformers onnx \"git+https://github.com/eaidova/optimum-intel.git@ea/whisper\" --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install -q \"openvino>=2023.2.0\" datasets  \"gradio>=4.0\" \"librosa\" \"soundfile\"\n",
    "!pip install -q \"nncf>=2.6.0\" \"jiwer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-10 13:13:30.357754: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "tokenizer_config.json: 100%|██████████| 805/805 [00:00<00:00, 502kB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 7.06MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.41M/2.41M [00:00<00:00, 5.43MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 4.69MB/s]\n",
      "normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 1.53MB/s]\n",
      "added_tokens.json: 100%|██████████| 34.6k/34.6k [00:00<00:00, 14.6MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 1.83k/1.83k [00:00<00:00, 5.29MB/s]\n",
      "config.json: 100%|██████████| 1.94k/1.94k [00:00<00:00, 12.1MB/s]\n",
      "model.safetensors: 100%|██████████| 151M/151M [00:10<00:00, 14.2MB/s] \n",
      "generation_config.json: 100%|██████████| 1.59k/1.59k [00:00<00:00, 6.52MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models saved to file system.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, AutoTokenizer\n",
    "\n",
    "model_id = \"openai/whisper-tiny.en\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "pt_model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id)\n",
    "pt_model.eval();\n",
    "\n",
    "tokenizer.save_pretrained(save_directory=\"./model\")\n",
    "pt_model.save_pretrained(save_directory=\"./model\")\n",
    "\n",
    "print(\"models saved to file system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ctc_decoders-1.1-py3.11-macosx-10.9-universal2.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m2024-01-10 13:18:49.382266: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Framework not specified. Using pt to export to ONNX.\n",
      "The task `automatic-speech-recognition` was manually specified, and past key values will not be reused in the decoding. if needed, please pass `--task automatic-speech-recognition-with-past` to export using the past key values.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using framework PyTorch: 2.1.2\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:1237: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_features.shape[-1] != expected_seq_length:\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:418: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:457: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "Using framework PyTorch: 2.1.2\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/modeling_attn_mask_utils.py:86: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1 or self.sliding_window is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/modeling_attn_mask_utils.py:161: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:425: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
      "Post-processing the exported models...\n",
      "Deduplicating shared (tied) weights...\n",
      "Found different candidate ONNX initializers (likely duplicate) for the tied weights:\n",
      "\tmodel.decoder.embed_tokens.weight: {'model.decoder.embed_tokens.weight'}\n",
      "\tproj_out.weight: {'onnx::MatMul_1557'}\n",
      "Removing duplicate initializer onnx::MatMul_1557...\n",
      "Validating ONNX model onnx/encoder_model.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (last_hidden_state)\n",
      "\t- Validating ONNX Model output \"last_hidden_state\":\n",
      "\t\t-[✓] (2, 1500, 384) matches (2, 1500, 384)\n",
      "\t\t-[✓] all values close (atol: 0.001)\n",
      "Validating ONNX model onnx/decoder_model.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (logits)\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 16, 51864) matches (2, 16, 51864)\n",
      "\t\t-[✓] all values close (atol: 0.001)\n",
      "The ONNX export succeeded and the exported model was saved at: onnx\n"
     ]
    }
   ],
   "source": [
    "!pip install pip install -q onnx onnxruntime 'optimum[exporters]'\n",
    "!optimum-cli export onnx --model model onnx/ --task 'automatic-speech-recognition'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
